{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Machine Learning Hackathon**\n\n## **Topic: Energy Usage Prediction System**\n    \n**Problem statement:**\n    \nCreate a methodology that utilizes data to **predict the electricity consumption** of\nhousehold appliances in low-energy homes, and **provide suggestions for optimizing\nenergy usage by identifying controllable factors.**\n\nThis approach will involve collecting data on various factors such as \n    a) appliance usage patterns *(data available)*, \n    b) weather conditions *(data available)*, and \n    c) other environmental factors *(data available)* \nthat affect energy consumption. The data will be analyzed to determine trends and patterns that can inform recommendations for efficient energy usage.\n\nThese **recommendations may include adjusting the timing of appliance usage, implementing energy-efficient appliances, and taking advantage of renewable energy sources.** *(domain knowledge required)*\n\nUltimately, the goal is to help homeowners reduce their electricity bills and minimize\ntheir environmental impact by maximizing the efficient use of energy.\n\nAttribute Information:\n    \n1. date : time year-month-day hour:minute:second\n2. Appliances : energy use ( transformed data), Logarithmic value from Wh\n3. lights, energy use of light fixtures in the house in Wh\n4. T1, Temperature in kitchen area, in Celsius\n5. RH_1, Humidity in kitchen area, in %\n6. T2, Temperature in living room area, in Celsius\n7. RH_2, Humidity in living room area, in %\n8. T3, Temperature in laundry room area\n9. RH_3, Humidity in laundry room area, in %\n10. T4, Temperature in office room, in Celsius\n11. RH_4, Humidity in office room, in %\n12. T5, Temperature in bathroom, in Celsius\n13. RH_5, Humidity in bathroom, in %\n14. T6, Temperature outside the building (north side), in Celsius\n15. RH_6, Humidity outside the building (north side), in %\n16. T7, Temperature in ironing room , in Celsius\n17. RH_7, Humidity in ironing room, in %\n18. T8, Temperature in teenager room 2, in Celsius\n19. RH_8, Humidity in teenager room 2, in %\n20. T9, Temperature in parents room, in Celsius\n21. RH_9, Humidity in parents room, in %\n22. To, Temperature outside (from XYZ weather station), in Celsius\n23. Pressure (from XYZ weather station), in mm Hg\n24. RH_out, Humidity outside (from XYZ weather station), in %\n25. Wind speed (from XYZ weather station), in m/s\n26. Visibility (from XYZ weather station), in km\n27. Tdewpoint (from XYZ weather station), Â°C\n28. rv1, Random variable 1, non dimensional\n29. rv2, Random variable 2, non dimensional","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"2 goals:\n\n1. Predicting Energy consumption patterns on unseen data\n2. Identifying drivers of consumption and recommending the controllable features for optimizing consumption","metadata":{}},{"cell_type":"markdown","source":"# Workflow\n\n- [1. Data Loading, Imports](#1)\n- [2. Preprocessing](#2)\n- [3. Feature Engineering,  Exploratory Data Analysis](#3)\n    >[3.1 Univariate Analysis](#3.1)\n    \n    >[3.2 Bivariate Analysis](#3.2)\n    \n    >[3.3 Multivariate Analysis](#3.3)\n    \n    >[3.4 Summary Observations and Recommendations](#3.4)\n- [4. Model Training, Hyperparameter tuning, Evaluation](#4)\n- [5. Recommendations, EDA Summary, Model Summary](#5)\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# 1. Data Loading, Imports\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport numpy as np\nfrom ydata_profiling import ProfileReport\n\n# Set plot style\nsns.set(color_codes=True)\n\nplt.rcParams['figure.figsize']=15,8\npd.pandas.set_option('display.max_columns', None)\npd.pandas.set_option('display.float_format', lambda x: '%.3f' % x)\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:41:44.022344Z","iopub.execute_input":"2023-06-18T17:41:44.023393Z","iopub.status.idle":"2023-06-18T17:41:45.240420Z","shell.execute_reply.started":"2023-06-18T17:41:44.023356Z","shell.execute_reply":"2023-06-18T17:41:45.239299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/household-energy-consumption-dataset/train.csv')\ndf_t = pd.read_csv('/kaggle/input/household-energy-consumption-dataset/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:41:47.075101Z","iopub.execute_input":"2023-06-18T17:41:47.075564Z","iopub.status.idle":"2023-06-18T17:41:47.210809Z","shell.execute_reply.started":"2023-06-18T17:41:47.075530Z","shell.execute_reply":"2023-06-18T17:41:47.209176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,12))\nsns.heatmap(df.corr(method = 'spearman'), fmt = '.2f',  annot = True, mask = np.triu(df.corr()))\nplt.savefig(f'corr-before-preprocessing.png')","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:41:53.533134Z","iopub.execute_input":"2023-06-18T17:41:53.533524Z","iopub.status.idle":"2023-06-18T17:41:56.795522Z","shell.execute_reply.started":"2023-06-18T17:41:53.533490Z","shell.execute_reply":"2023-06-18T17:41:56.794328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# 2. Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Dataframe description**","metadata":{}},{"cell_type":"code","source":"# lets start with the df_customer_demographic \nprint('Shape:', df.shape)\n\nprint('='*80)\nprint('Information about dataset \\n',df.info(),'\\n')\n\nprint('='*80)\nprint('Null Values')\nmissing_indices = set()\nfor index, row in df.iterrows():\n    if row.isnull().any():\n        missing_indices.add(index)\n(len(missing_indices), df.isna().sum().sum()),df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:00.959641Z","iopub.execute_input":"2023-06-18T17:42:00.960066Z","iopub.status.idle":"2023-06-18T17:42:03.341128Z","shell.execute_reply.started":"2023-06-18T17:42:00.960035Z","shell.execute_reply":"2023-06-18T17:42:03.339985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('='*80)\nprint('First 5 rows \\n')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:06.663843Z","iopub.execute_input":"2023-06-18T17:42:06.664319Z","iopub.status.idle":"2023-06-18T17:42:06.691057Z","shell.execute_reply.started":"2023-06-18T17:42:06.664282Z","shell.execute_reply":"2023-06-18T17:42:06.689539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('='*80)\nprint('Describe the dataset \\n')\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:08.987525Z","iopub.execute_input":"2023-06-18T17:42:08.987963Z","iopub.status.idle":"2023-06-18T17:42:09.093806Z","shell.execute_reply.started":"2023-06-18T17:42:08.987929Z","shell.execute_reply":"2023-06-18T17:42:09.092469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Duplicates**","metadata":{}},{"cell_type":"code","source":"print('Duplicates count:\\t',df.duplicated().sum())","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:12.639193Z","iopub.execute_input":"2023-06-18T17:42:12.639576Z","iopub.status.idle":"2023-06-18T17:42:12.669997Z","shell.execute_reply.started":"2023-06-18T17:42:12.639540Z","shell.execute_reply":"2023-06-18T17:42:12.668515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Outlier Analysis and Handling**","metadata":{}},{"cell_type":"code","source":"## Checking for skewness/outliers\nprint('Feature Skewness \\n','='*80)\ndf.skew()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:14.400037Z","iopub.execute_input":"2023-06-18T17:42:14.400506Z","iopub.status.idle":"2023-06-18T17:42:14.430782Z","shell.execute_reply.started":"2023-06-18T17:42:14.400473Z","shell.execute_reply":"2023-06-18T17:42:14.429446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\n## Let's identify outliers, beyond 2 standard deviations from feature means\noutlier_row_indices = set()\noutlier_features = dict()\nfor column in df.drop(['ID','date'], axis =1).columns:\n    z_scores = stats.zscore(df[column])\n    outlier_row_indices.update(np.where(np.abs(z_scores) > 3)[0])\n    outlier_features[column]=len(np.where(np.abs(z_scores) > 3)[0])\n    \nprint('No ofrows with outlier attributes:\\t',len(outlier_row_indices))\nprint('Percentage of rows with outlier attributes in dataset:',len(outlier_row_indices)/ df.shape[0])\nprint('\\n', '='*80)\nprint('Feature wise outlier counts')\noutlier_features","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:17.444760Z","iopub.execute_input":"2023-06-18T17:42:17.445205Z","iopub.status.idle":"2023-06-18T17:42:17.502131Z","shell.execute_reply.started":"2023-06-18T17:42:17.445170Z","shell.execute_reply":"2023-06-18T17:42:17.500683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on psychrometric charts, features relative humidity is defined for a particular tempratre and hence t1-t9 and rh_1 to rh_9 are pair wise not correlated.\n","metadata":{}},{"cell_type":"code","source":"numerical_columns = df.select_dtypes(include=['int64', 'float64']).drop('ID', axis = 1).drop('lights', axis = 1).drop('appliances', axis = 1).columns.tolist()\n\n\nfig, axes = plt.subplots(nrows=20, ncols=4, figsize=(12, 50))\n\naxes = axes.flatten()\n\nfor i, variable in enumerate(numerical_columns):\n    sns.boxplot(x=df[variable], ax=axes[i]) \n    axes[i].set_title(variable) \n#     plt.savefig(f'boxplot-{variable}.jpg')\n    \nif len(numerical_columns) < len(axes):\n    for j in range(len(numerical_columns), len(axes)):\n        fig.delaxes(axes[j])\n\nfig.tight_layout()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:20.635431Z","iopub.execute_input":"2023-06-18T17:42:20.635811Z","iopub.status.idle":"2023-06-18T17:42:27.286494Z","shell.execute_reply.started":"2023-06-18T17:42:20.635782Z","shell.execute_reply":"2023-06-18T17:42:27.285507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<a id=\"3\"></a>\n# 3. Feature Engineering,  Exploratory Data Analysis\n\n\n","metadata":{}},{"cell_type":"markdown","source":"**Reformat timestamp feature and extract date, month, week, day, hour**\n- df\n- df_t","metadata":{"execution":{"iopub.status.busy":"2023-06-17T08:15:46.035302Z","iopub.execute_input":"2023-06-17T08:15:46.035643Z","iopub.status.idle":"2023-06-17T08:15:46.039948Z","shell.execute_reply.started":"2023-06-17T08:15:46.035616Z","shell.execute_reply":"2023-06-17T08:15:46.038936Z"}}},{"cell_type":"code","source":"## df\ndf['month'] = pd.to_datetime(df['date']).dt.month\ndf['date_2'] = pd.to_datetime(df['date']).dt.date\ndf['time'] = pd.to_datetime(df['date']).dt.time\ndf['week'] = pd.to_datetime(df['date']).dt.week\ndf['day_num'] = pd.to_datetime(df['date']).dt.dayofweek\ndf['time'] = pd.to_datetime(df['date']).dt.time\ndf['day_type'] = pd.to_datetime(df['date']).dt.dayofweek.apply(lambda x: '0' if x < 5 else '1')\ndf['week_num'] = pd.to_datetime(df['date']).dt.week\n\ndf[\"hour\"] = pd.to_datetime(df[\"date\"]).dt.hour\ndf[\"weekday\"] = pd.to_datetime(df[\"date\"]).dt.weekday","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:31.823239Z","iopub.execute_input":"2023-06-18T17:42:31.823721Z","iopub.status.idle":"2023-06-18T17:42:31.938880Z","shell.execute_reply.started":"2023-06-18T17:42:31.823679Z","shell.execute_reply":"2023-06-18T17:42:31.937613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## df_t\ndf_t['month'] = pd.to_datetime(df_t['date']).dt.month\ndf_t['date_2'] = pd.to_datetime(df_t['date']).dt.date\ndf_t['time'] = pd.to_datetime(df_t['date']).dt.time\ndf_t['week'] = pd.to_datetime(df_t['date']).dt.week\ndf_t['day_num'] = pd.to_datetime(df_t['date']).dt.dayofweek\ndf_t['time'] = pd.to_datetime(df_t['date']).dt.time\ndf_t['day_type'] = pd.to_datetime(df_t['date']).dt.dayofweek.apply(lambda x: '0' if x < 5 else '1')\ndf_t['week_num'] = pd.to_datetime(df_t['date']).dt.week\n\ndf_t[\"hour\"] = pd.to_datetime(df_t[\"date\"]).dt.hour\ndf_t[\"weekday\"] = pd.to_datetime(df_t[\"date\"]).dt.weekday","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:34.383789Z","iopub.execute_input":"2023-06-18T17:42:34.384256Z","iopub.status.idle":"2023-06-18T17:42:34.433366Z","shell.execute_reply.started":"2023-06-18T17:42:34.384219Z","shell.execute_reply":"2023-06-18T17:42:34.432036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_temp = [\"t1\",\"t2\",\"t3\",\"t4\",\"t5\",\"t6\",\"t7\",\"t8\",\"t9\"]\n\ncol_hum = [\"rh_1\",\"rh_2\",\"rh_3\",\"rh_4\",\"rh_5\",\"rh_6\",\"rh_7\",\"rh_8\",\"rh_9\"]\n\ncol_weather = [\"t_out\", \"tdewpoint\",\"rh_out\",\"press_mm_hg\",\n                \"windspeed\",\"visibility\"] \ncol_light = [\"lights\"]\n\ncol_randoms = [\"rv1\", \"rv2\"]\n\ncol_time = [\"hour\", \"weekday\"]\n\ncol_target = [\"appliances\"]","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:40.087477Z","iopub.execute_input":"2023-06-18T17:42:40.088114Z","iopub.status.idle":"2023-06-18T17:42:40.095497Z","shell.execute_reply.started":"2023-06-18T17:42:40.087851Z","shell.execute_reply":"2023-06-18T17:42:40.094051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['day_num']].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:43.277177Z","iopub.execute_input":"2023-06-18T17:42:43.278514Z","iopub.status.idle":"2023-06-18T17:42:43.297304Z","shell.execute_reply.started":"2023-06-18T17:42:43.278440Z","shell.execute_reply":"2023-06-18T17:42:43.295566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3.1\"></a>\n## 3.1 Univariate Analysis","metadata":{}},{"cell_type":"markdown","source":"Lets understand feature distributions","metadata":{}},{"cell_type":"code","source":"len(df.columns)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:48.065957Z","iopub.execute_input":"2023-06-18T17:42:48.066399Z","iopub.status.idle":"2023-06-18T17:42:48.074658Z","shell.execute_reply.started":"2023-06-18T17:42:48.066365Z","shell.execute_reply":"2023-06-18T17:42:48.073296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:49.493985Z","iopub.execute_input":"2023-06-18T17:42:49.495226Z","iopub.status.idle":"2023-06-18T17:42:49.504733Z","shell.execute_reply.started":"2023-06-18T17:42:49.495147Z","shell.execute_reply":"2023-06-18T17:42:49.502815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_columns = df.select_dtypes(include=['int64', 'float64']).drop(['ID','month','rv1','rv2','visibility', 'windspeed',\n       'week','day_num', 'week_num', 'lights'], axis = 1).columns.tolist()\n\nfig, axes = plt.subplots(nrows=5, ncols=5, figsize=(15, 20))\n\naxes = axes.flatten()\n\nfor i, variable in enumerate(numerical_columns):\n    df[variable].hist(ax=axes[i])\n    axes[i].set_title(variable) \n    \nfig.tight_layout()  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:42:53.944255Z","iopub.execute_input":"2023-06-18T17:42:53.944720Z","iopub.status.idle":"2023-06-18T17:43:01.540110Z","shell.execute_reply.started":"2023-06-18T17:42:53.944682Z","shell.execute_reply":"2023-06-18T17:43:01.538848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['month']==1].groupby('date_2').agg({'appliances':'mean'}).appliances","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:43:07.998019Z","iopub.execute_input":"2023-06-18T17:43:07.998545Z","iopub.status.idle":"2023-06-18T17:43:08.017247Z","shell.execute_reply.started":"2023-06-18T17:43:07.998503Z","shell.execute_reply":"2023-06-18T17:43:08.015641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inferences**\n1. **`rv1` and `rv2` features show no visible variance.** We'll verify their correlation strength against the target and make a retain/drop decision.\n2. **`lights` feature has largely zero valuess.** We'll verify their correlation strength against the target and make a retain/drop decision.\n3. **Temperature and Relative Humidity features'** histograms as captured by sensors 0-9 have **similar distributions.** From **psychrometric properties of ambient air,** relative humidity of air is defined for a given temperature. So it follows that, unless air is conditioned with humidity adjustments, **`t0-t9` and `rh_0-rh_9` should be pairwise correlated**.\n4. **Windspeed and relative humidity move in the opposite directions** and the same is observed in weather station **`windspeed`** and **`rh_out`** features.\n5. The day-wise consumption reveals some insights during winter and summer months of Jan and May. The transition spring months seems to see randm consumption.","metadata":{"execution":{"iopub.status.busy":"2023-06-17T09:14:35.672359Z","iopub.execute_input":"2023-06-17T09:14:35.672734Z","iopub.status.idle":"2023-06-17T09:14:35.68139Z","shell.execute_reply.started":"2023-06-17T09:14:35.672704Z","shell.execute_reply":"2023-06-17T09:14:35.679635Z"}}},{"cell_type":"markdown","source":"<a id=\"3.2\"></a>\n## 3.2 Bivariate Analysis\n","metadata":{}},{"cell_type":"markdown","source":"**Daily consumption trendline**","metadata":{}},{"cell_type":"code","source":"plt.style.use('ggplot')\nmonths = [1, 2, 3, 4, 5]\nm_names = ['January', 'February', 'March', 'April', 'May']\nsubplots = [511, 512, 513, 514, 515]\n\nfig, axs = plt.subplots(len(months), 1, figsize=(15, 12))\n\nfor i, (month, m_name) in enumerate(zip(months, m_names)):\n    ax = axs[i]\n    df_month = df[df['month'] == month]\n    sorted_dates = sorted(list(df_month['date_2'].unique()))\n\n    # Get the mean appliance values for the current month\n    y = df_month.groupby('date_2').agg({'appliances': 'mean'}).appliances.to_list()\n\n    ax.plot(sorted_dates, y, color='green', linewidth=1.7)\n    ax.set_title(m_name)\n\n    # Set the x-axis tick positions and labels\n    day_of_week_labels = [date.strftime('%a') for date in sorted_dates]\n    day_of_month_labels = [date.day for date in sorted_dates] \n    \n    x_labels = \\\n    [f'{dow}\\n{dom}' for dow, dom in zip(day_of_week_labels, day_of_month_labels)]  \n    # Concatenate labels\n\n    ax.set_xticks(sorted_dates)\n    ax.set_xticklabels(x_labels)\n    ax.tick_params(axis='x', rotation=0)\n\nplt.suptitle('Daily Mean Log Appliance Power Consumption')\nfig.text(0, 0.5, 'Appliance Energy Consumption', va='center', rotation='vertical')\nfig.text(0.5, 0, 'Day of the month', ha='center')\nplt.tight_layout()\nplt.savefig('Daily Mean Log Appliance Power Consumption.png')\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:43:20.412662Z","iopub.execute_input":"2023-06-18T17:43:20.413125Z","iopub.status.idle":"2023-06-18T17:43:24.698603Z","shell.execute_reply.started":"2023-06-18T17:43:20.413060Z","shell.execute_reply":"2023-06-18T17:43:24.697660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Daily Consumption trends:\n* Onset of the weekend: Upward trend in energy consumption\n* Consistent downward trend in consumption levels at start of the week (pivot points highlighted in blue)","metadata":{}},{"cell_type":"code","source":"df['hour'] = pd.to_datetime(df['date']).dt.strftime('%H').astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:43:32.518553Z","iopub.execute_input":"2023-06-18T17:43:32.519348Z","iopub.status.idle":"2023-06-18T17:43:32.601552Z","shell.execute_reply.started":"2023-06-18T17:43:32.519301Z","shell.execute_reply":"2023-06-18T17:43:32.599706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WeekendDf = df[df.day_type == '1'].groupby('hour')['appliances'].median().reset_index()\nWeekdayDf = df[df.day_type == '0'].groupby('hour')['appliances'].median().reset_index()\n\n\nWeekendDf['appliances'] = np.exp(WeekendDf['appliances'])\nWeekdayDf['appliances'] = np.exp(WeekdayDf['appliances'])\n\nbar_width = 0.35\n\nx = np.arange(len(WeekendDf['hour']))\n\nfig, ax = plt.subplots(figsize=(15, 4))\n\nax.bar(x - bar_width/2, WeekendDf['appliances'], bar_width, label='Weekend')\n\nax.bar(x + bar_width/2, WeekdayDf['appliances'], bar_width, label='Weekday')\n\nax.set_xticks(x)\nax.set_xticklabels(WeekendDf['hour'])\n\nax.set_xlabel('Hour')\nax.set_ylabel('Appliances')\nax.set_title('Hourly Trends')\n\nax.legend()\n\nplt.savefig(f'Weekend-vc-Weekday-hourly-trends.png')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:43:36.666804Z","iopub.execute_input":"2023-06-18T17:43:36.667289Z","iopub.status.idle":"2023-06-18T17:43:37.608029Z","shell.execute_reply.started":"2023-06-18T17:43:36.667250Z","shell.execute_reply":"2023-06-18T17:43:37.606917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Weekday vs Weekend Hourly Energy Consumption: Inferences\n* Uptick in Energy consumption levels between 8AM to 9PM\n* Peak Energy Consumption between the hours 5PM and 9PM\n* Weekend daytime energy consumption is greater than that during weekdays.","metadata":{}},{"cell_type":"markdown","source":"**Ambient Morning Temperature (tout) tredline**","metadata":{}},{"cell_type":"code","source":"def corr_map(df, title, method='spearman', numeric_only = True, tick_size = 10, annot_size=8, annot_kws=8):\n    mask = np.triu(np.ones_like(df.corr(numeric_only=numeric_only), dtype=bool))\n    heatmap = sns.heatmap(df.corr(method=method, numeric_only = numeric_only), fmt = '.2f',  annot = True, annot_kws = {'size': annot_kws}, mask=mask, cmap='BrBG')#\n    plt.xticks(rotation=80, fontsize= tick_size)\n    plt.yticks( fontsize= tick_size)\n\n    heatmap.set_title(title, fontdict={'fontsize':annot_size}, pad=12)\n    plt.show();","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:43:42.956921Z","iopub.execute_input":"2023-06-18T17:43:42.958468Z","iopub.status.idle":"2023-06-18T17:43:42.965540Z","shell.execute_reply.started":"2023-06-18T17:43:42.958421Z","shell.execute_reply":"2023-06-18T17:43:42.964321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['inv_log_appliance'] = np.exp(df['appliances'])","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:43:45.270745Z","iopub.execute_input":"2023-06-18T17:43:45.271656Z","iopub.status.idle":"2023-06-18T17:43:45.278592Z","shell.execute_reply.started":"2023-06-18T17:43:45.271608Z","shell.execute_reply":"2023-06-18T17:43:45.277193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['appliances'].max(), df['inv_log_appliance'].max()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:43:48.731617Z","iopub.execute_input":"2023-06-18T17:43:48.732024Z","iopub.status.idle":"2023-06-18T17:43:48.742755Z","shell.execute_reply.started":"2023-06-18T17:43:48.731990Z","shell.execute_reply":"2023-06-18T17:43:48.741007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_map(df.drop(['month', 'date_2', 'time','rv1','rv2','visibility', 'windspeed',\n       'week','day_num', 'day_type', 'week_num'], axis =1), method='pearson' , title='Feature Correlations')","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:43:50.618248Z","iopub.execute_input":"2023-06-18T17:43:50.618720Z","iopub.status.idle":"2023-06-18T17:43:53.082529Z","shell.execute_reply.started":"2023-06-18T17:43:50.618686Z","shell.execute_reply":"2023-06-18T17:43:53.081582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3.3\"></a>\n## 3.3 Multivariate Analysis\n","metadata":{}},{"cell_type":"code","source":"df['temprature_inside'] = df[['t1', 't2', 't3', 't4', 't5', 't7', 't8', 't9']].mean(axis=1)\ndf['temprature_outside'] = df['t6']\n\ndf['inv_log_appliances'] = np.exp(df['appliances']) - 30\n\nMultvariateDF = df[['week_num', 'temprature_inside', 'temprature_outside', 'windspeed', 'inv_log_appliances']].groupby('week_num')[['temprature_inside', 'temprature_outside', 'windspeed', 'inv_log_appliances']].median().reset_index()\nMultvariateDF['windspeed'] = MultvariateDF['windspeed'] * 6 +10\n\nbar_width = 0.35\nbar_offset = bar_width / 2\n\nfig, ax = plt.subplots(figsize=(20,8)) \n\nplt.bar(MultvariateDF['week_num'], MultvariateDF['temprature_inside'], width=bar_width, align='center', label='temprature Inside')\n\nplt.bar(np.array(MultvariateDF['week_num']) + bar_offset, MultvariateDF['temprature_outside'], width=bar_width, align='center', label='temprature Outside')\n\n\nplt.plot(MultvariateDF['week_num'], MultvariateDF['windspeed'], label='Wind Speed', c = 'black', linestyle = 'dashed')\n\nplt.plot(MultvariateDF['week_num'], MultvariateDF['inv_log_appliances'], label='Inv Log Appliances', linestyle = 'dotted')\n\n\n\nplt.xlabel('Week Number')\nplt.ylabel('')\nplt.title('Appliances trends with temprature Inside and Outside')\nplt.xticks(MultvariateDF['week_num'])\n\nplt.legend()\n\nplt.savefig(f'Appliances-trends-with-temprature-Inside-and-Outside.png')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:44:37.200818Z","iopub.execute_input":"2023-06-18T17:44:37.201636Z","iopub.status.idle":"2023-06-18T17:44:38.348606Z","shell.execute_reply.started":"2023-06-18T17:44:37.201594Z","shell.execute_reply":"2023-06-18T17:44:38.347289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['humidity_inside'] = df[['rh_1', 'rh_2', 'rh_3', 'rh_4', 'rh_5', 'rh_7', 'rh_8', 'rh_9']].mean(axis=1)\ndf['humidity_outside'] = df['rh_6']\n\ndf['inv_log_appliances'] = np.exp(df['appliances']) - 30\n\nMultvariateDF = df[['week_num', 'humidity_inside', 'humidity_outside', 'windspeed', 'inv_log_appliances']].groupby('week_num')[['humidity_inside', 'humidity_outside', 'windspeed', 'inv_log_appliances']].median().reset_index()\nMultvariateDF['windspeed'] = MultvariateDF['windspeed'] * 6 +10\n\nbar_width = 0.35\nbar_offset = bar_width / 2\n\nfig, ax = plt.subplots(figsize=(20,8)) \n\nplt.bar(MultvariateDF['week_num'], MultvariateDF['humidity_inside'], width=bar_width, align='center', label='Humidity Inside')\n\nplt.bar(np.array(MultvariateDF['week_num']) + bar_offset, MultvariateDF['humidity_outside'], width=bar_width, align='center', label='Humidity Outside')\n\n\nplt.plot(MultvariateDF['week_num'], MultvariateDF['windspeed'], label='Wind Speed', c = 'black', linestyle = 'dashed')\n\nplt.plot(MultvariateDF['week_num'], MultvariateDF['inv_log_appliances'], label='Log Inv Appliances', linestyle = 'dotted')\n\n\n\nplt.xlabel('Week Number')\nplt.ylabel('')\nplt.title('Appliances trends with Humidity Inside and Outside')\nplt.xticks(MultvariateDF['week_num'])\n\nplt.legend()\n\nplt.savefig(f'Appliances-trends-with-humidity-Inside-and-Outside.png')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:44:42.645662Z","iopub.execute_input":"2023-06-18T17:44:42.646131Z","iopub.status.idle":"2023-06-18T17:44:43.746419Z","shell.execute_reply.started":"2023-06-18T17:44:42.646077Z","shell.execute_reply":"2023-06-18T17:44:43.745219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* There is a **significant difference in mean inside temperature and outside temperature,** which suggests that the space is being **artificially heated.** This also follows our initial hypothesis from the weak correlation between internal temperature and internal humidity.\n* We also observe that the **inverse log transformed target (appliance power usage at actuals) sharply follows the mean internal temperature changes.** This suggests that **internal  heating is a significant driver of household energy consumption.** We can save on consumption, if we use \n    - Energy efficient heating system\n    - Better insulation \n    - Fixing air leakages from the interiors to the exteriors of the house","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3.4\"></a>\n## 3.4 Summary Observations and Recommendations","metadata":{}},{"cell_type":"markdown","source":"**Observations**\nTemperature columns - Temperature inside the house varies between 14.89 Deg & 29.85 Deg , temperatire outside (T6) varies between -6.06 Deg to 28.29 Deg . The reason for this variation is sensors are kept outside the house\n\n**Humidiy columns** - Humidity inside house varies is between 20.60% to 63.36% with exception of RH_5 (Bathroom) and RH_6 (Outside house) which varies between 29.82% to 96.32% and 1% to 99.9% respectively.\n\n**Appliances** - 75% of Appliance consumption is less than 100 Wh . With the maximum consumption of 1080 Wh (inverse log transformed target) , there will be outliers in this column and there are small number of cases where consumption is very high\n\n**Lights column** - Intially we believed lights column will be able to give useful information . With 11438 0 (zero) enteries in 14801 rows , this column will not add any value to the model . We believed light consumption along with humidity level in a room will give idea about human presence in the room and hence its impact on Appliance consumption. Hence, we will dropping this column","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n# 4. Model Training, Hyperparameter tuning, Evaluation\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing, model_selection, metrics\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\nfrom sklearn.neural_network import MLPRegressor\nimport xgboost as xgb\nfrom sklearn import neighbors\nfrom sklearn.svm import SVR\n\nimport time\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:44:54.330392Z","iopub.execute_input":"2023-06-18T17:44:54.330944Z","iopub.status.idle":"2023-06-18T17:44:54.510511Z","shell.execute_reply.started":"2023-06-18T17:44:54.330903Z","shell.execute_reply":"2023-06-18T17:44:54.509159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 75% of the data is usedfor the training of the models and the rest is used for testing\ntrain, test = train_test_split(df,test_size=0.25,random_state=40)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:44:57.970740Z","iopub.execute_input":"2023-06-18T17:44:57.971212Z","iopub.status.idle":"2023-06-18T17:44:57.988267Z","shell.execute_reply.started":"2023-06-18T17:44:57.971177Z","shell.execute_reply":"2023-06-18T17:44:57.986694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# These features will be used to select the model, as it has train and test  split is available\nfeature_vars = col_temp + col_hum + col_weather +   col_time\ntarget_vars = col_target\n\n\n# We use below features after selecting the final model\nmodel_features_vars = col_temp + col_hum + col_weather +  col_time\nmodel_target_vars = col_target","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:44:59.760516Z","iopub.execute_input":"2023-06-18T17:44:59.760992Z","iopub.status.idle":"2023-06-18T17:44:59.767380Z","shell.execute_reply.started":"2023-06-18T17:44:59.760952Z","shell.execute_reply":"2023-06-18T17:44:59.766069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split training dataset into independent and dependent varibales\ntrain_X = train[feature_vars]\ntrain_y = train[target_vars]\n\n#Split testing dataset into independent and dependent varibales\ntest_X = test[feature_vars]\ntest_y = test[target_vars]\n\n# We use below features after selecting the final model\nmodel_train_X = train[feature_vars]\nmodel_train_y = train[target_vars]","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:45:02.699859Z","iopub.execute_input":"2023-06-18T17:45:02.700362Z","iopub.status.idle":"2023-06-18T17:45:02.716518Z","shell.execute_reply.started":"2023-06-18T17:45:02.700323Z","shell.execute_reply":"2023-06-18T17:45:02.714691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = [\n           ['Lasso', Lasso()],\n           ['Ridge', Ridge()],\n           ['K-Neighbors Regressor',  neighbors.KNeighborsRegressor()],\n           ['SVR' , SVR(kernel='rbf')],\n           ['Random Forest',RandomForestRegressor()],\n           ['Extra Tree Regressor',ExtraTreesRegressor()],\n           ['Gradient Boosting Classifier', GradientBoostingRegressor()] ,\n           ['XGB Regressor', xgb.XGBRegressor()] ,\n           ['MLP Regressor', MLPRegressor(  activation='relu', solver='adam',learning_rate='adaptive',max_iter=1000,learning_rate_init=0.01,alpha=0.01)]\n         ]","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:45:05.760404Z","iopub.execute_input":"2023-06-18T17:45:05.760893Z","iopub.status.idle":"2023-06-18T17:45:05.769500Z","shell.execute_reply.started":"2023-06-18T17:45:05.760858Z","shell.execute_reply":"2023-06-18T17:45:05.767976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_data = []\nfor name,curr_model in models :\n    curr_model_data = {}\n    curr_model.random_state = 78\n    curr_model_data[\"Name\"] = name\n    start = time.time()\n    curr_model.fit(train_X,train_y)\n    end = time.time()\n    curr_model_data[\"Train_Time\"] = end - start\n    curr_model_data[\"Train R2 Score\"] = metrics.r2_score(train_y,curr_model.predict(train_X))\n    curr_model_data[\"Validate R2 Score\"] = metrics.r2_score(test_y,curr_model.predict(test_X))\n    curr_model_data[\"Test RMSE Score\"] = sqrt(mean_squared_error(test_y,curr_model.predict(test_X)))\n    model_data.append(curr_model_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:45:09.152080Z","iopub.execute_input":"2023-06-18T17:45:09.152556Z","iopub.status.idle":"2023-06-18T17:46:15.259929Z","shell.execute_reply.started":"2023-06-18T17:45:09.152521Z","shell.execute_reply":"2023-06-18T17:46:15.258367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelComparison = pd.DataFrame(model_data)\nmodelComparison = modelComparison.sort_values(by=['Train R2 Score', 'Validate R2 Score', 'Test RMSE Score']).reset_index()\nmodelComparison","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:46:20.748472Z","iopub.execute_input":"2023-06-18T17:46:20.749110Z","iopub.status.idle":"2023-06-18T17:46:20.770577Z","shell.execute_reply.started":"2023-06-18T17:46:20.749040Z","shell.execute_reply":"2023-06-18T17:46:20.769111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelComparison.set_index('Name', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:47:45.254789Z","iopub.execute_input":"2023-06-18T17:47:45.255272Z","iopub.status.idle":"2023-06-18T17:47:45.263101Z","shell.execute_reply.started":"2023-06-18T17:47:45.255238Z","shell.execute_reply":"2023-06-18T17:47:45.261788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelComparison[modelComparison['Train R2 Score'] > 0][['Train R2 Score', 'Validate R2 Score']].plot.bar()\n\n# plt.figure(figsize = (8, 4))\nplt.xlabel('')\nplt.xticks(rotation = 45)\nplt.ylabel('')\nplt.title('Models Comparision')\n\nplt.savefig(f'Models-comparision.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:47:56.079494Z","iopub.execute_input":"2023-06-18T17:47:56.079971Z","iopub.status.idle":"2023-06-18T17:47:56.799334Z","shell.execute_reply.started":"2023-06-18T17:47:56.079937Z","shell.execute_reply":"2023-06-18T17:47:56.798056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* By comparing all the model, found `Extra Tree Regressor` giving best results. \n* Further, we will implement hyperparameters tunning on `Extra Tree Regressor`\n* Below are the best features, observed for `Extra Tree Regressor`","metadata":{}},{"cell_type":"code","source":"xtr = ExtraTreesRegressor(criterion='poisson',max_depth=100,max_features='log2', n_estimators=350,n_jobs=-1,random_state=40)\nxtr.fit(model_train_X,model_train_y)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:49:56.409742Z","iopub.execute_input":"2023-06-18T17:49:56.410219Z","iopub.status.idle":"2023-06-18T17:50:00.100057Z","shell.execute_reply.started":"2023-06-18T17:49:56.410187Z","shell.execute_reply":"2023-06-18T17:50:00.098776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics.r2_score(test_y,xtr.predict(test_X))","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:50:08.031896Z","iopub.execute_input":"2023-06-18T17:50:08.032356Z","iopub.status.idle":"2023-06-18T17:50:08.321214Z","shell.execute_reply.started":"2023-06-18T17:50:08.032325Z","shell.execute_reply":"2023-06-18T17:50:08.320208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preparing the test Data for predictions","metadata":{}},{"cell_type":"code","source":"df_t[\"hour\"] = pd.to_datetime(df_t[\"date\"]).dt.hour\ndf_t[\"weekday\"] = pd.to_datetime(df_t[\"date\"]).dt.weekday","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:52:48.483178Z","iopub.execute_input":"2023-06-18T17:52:48.483618Z","iopub.status.idle":"2023-06-18T17:52:48.496302Z","shell.execute_reply.started":"2023-06-18T17:52:48.483585Z","shell.execute_reply":"2023-06-18T17:52:48.494922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = list(df_t['ID'])\nmodel_test_X = df_t[col_temp + col_hum + col_weather + col_time ]","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:53:11.671919Z","iopub.execute_input":"2023-06-18T17:53:11.672967Z","iopub.status.idle":"2023-06-18T17:53:11.683165Z","shell.execute_reply.started":"2023-06-18T17:53:11.672910Z","shell.execute_reply":"2023-06-18T17:53:11.682130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = xtr.predict(model_test_X)\nsub_xtree = pd.DataFrame({\"ID\": ids, \"appliances\":list(pred)})\nsub_xtree.to_csv(\"/kaggle/working/sub_xtree.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:54:05.146189Z","iopub.execute_input":"2023-06-18T17:54:05.146816Z","iopub.status.idle":"2023-06-18T17:54:05.423574Z","shell.execute_reply.started":"2023-06-18T17:54:05.146771Z","shell.execute_reply":"2023-06-18T17:54:05.422398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_xtree.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T17:54:19.343885Z","iopub.execute_input":"2023-06-18T17:54:19.344760Z","iopub.status.idle":"2023-06-18T17:54:19.358727Z","shell.execute_reply.started":"2023-06-18T17:54:19.344707Z","shell.execute_reply":"2023-06-18T17:54:19.357157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Achieved accuracy : 78.45 %**","metadata":{}}]}